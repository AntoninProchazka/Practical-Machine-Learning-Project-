---
title: "code_project_AP"
author: "Antonin Prochazka"
date: "Wednesday, November 19, 2014"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.




1) Firstly, I loaded the packages and the training data. I divided the data (given training set only) into two sets: Training set (60%) and testing set (40%)

```{r}

library(ggplot2); library(caret);

Data = read.csv("pml-training.csv", header = TRUE, sep = "," );
#summary(Data)

inTrain <- createDataPartition(y=Data$classe,
                              p=0.6, list=FALSE)
training <- Data[inTrain,]
testing <- Data[-inTrain,]
dim(training); dim(testing)

```


2) Secondly, I took a look at the data using summary command (and also in a spreadsheet application) and I realized that there is a lot of missing values or NAN values. It was specific for entire columns, therefore I decided to select only columns which seemed usable. I selected the predictors using following code:

```{r}
keeps <- c(
"num_window",  "roll_belt",	"pitch_belt",	"yaw_belt",	"total_accel_belt",
"gyros_belt_x",	"gyros_belt_y",	"gyros_belt_z",	"accel_belt_x",	"accel_belt_y",
"accel_belt_z",	"magnet_belt_x",	"magnet_belt_y",	"magnet_belt_z",	"roll_arm",	
"pitch_arm",	"yaw_arm",		"total_accel_arm", "gyros_arm_x",	"gyros_arm_y",	"gyros_arm_z",
"accel_arm_x",	"accel_arm_y",	"accel_arm_z",	"magnet_arm_x",	"magnet_arm_y",	
"magnet_arm_z", "roll_dumbbell",	"pitch_dumbbell",	"yaw_dumbbell", "total_accel_dumbbell",
"gyros_dumbbell_x",	"gyros_dumbbell_y",	"gyros_dumbbell_z",	"accel_dumbbell_x",
"accel_dumbbell_y",	"accel_dumbbell_z",	"magnet_dumbbell_x",	"magnet_dumbbell_y",
"magnet_dumbbell_z",	"roll_forearm",		"pitch_forearm",		"yaw_forearm",
"gyros_forearm_x",	"gyros_forearm_y",	"gyros_forearm_z",	"accel_forearm_x",	
"accel_forearm_y",	"accel_forearm_z",	"magnet_forearm_x",	"magnet_forearm_y",
"magnet_forearm_z",	"classe"
)


training_selection = training[keeps]
#summary(training_selection)

```

3) Then I displayed some plot of predictors that seemd to be general and important, such as "total_accel_belt" or "total_accel_arm" and "total_accel_dumbbell". The dependences weren´t strong and it seemed  that the model has to be based on a bit advanced algorithm. Therefore I decided to use a non linear and advanced algorithm - Random forests. I am attaching one graph from visualization of the features. 



```{r, echo=FALSE}
qplot(num_window,total_accel_arm, color=classe, data=training_selection)
```


4) Then I fitted the Random forest model using following code. In preprocessing, I set all the NA values to be removed (I had been removing the columns in previous preprocessing. However, it could happen that some NA values rested in the data). In this point I tried also PCA in preprocessing (to reduce computational demands) but it reduced the accuracy a lot. It confirms an assumption that PCA is useful especially for linear models. I left default settings for train controlling (Bootstrapping) as well as the metrics to maximalize (Accuracy, RMSE).  

```{r}
args(trainControl)
modelFit <- train(classe ~.,data=training_selection,preProcess.na.remove = TRUE, method="rf")
modelFit
modelFit$finalModel
```

5) Then I predicted the classes for my testing set (40% of given training set) and I created a confusion matrix. The statistics didn´t vary a lot from the previous ModelFit statistics. It shows that algorithm works well also for an independent data.

```{r}
predictions <- predict(modelFit,newdata=testing)
predictions

confusionMatrix(predictions,testing$classe)
```


6) Finally, I predicted 20 given cases (given test set) using following code:

```{r}
Data_TS = read.csv("pml-testing.csv", header = TRUE, sep = "," );
#summary(Data_TS)

predictions <- predict(modelFit,newdata=Data_TS)
predictions

```



