<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title></title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p>This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <a href="http://rmarkdown.rstudio.com">http://rmarkdown.rstudio.com</a>.</p>

<p>1) Firstly, I loaded the packages and the training data. I divided the data (given training set only) into two sets: Training set (60%) and testing set (40%)</p>

<pre><code class="r">
library(ggplot2); library(caret);

Data = read.csv(&quot;pml-training.csv&quot;, header = TRUE, sep = &quot;,&quot; );
#summary(Data)

inTrain &lt;- createDataPartition(y=Data$classe,
                              p=0.6, list=FALSE)
training &lt;- Data[inTrain,]
testing &lt;- Data[-inTrain,]
dim(training); dim(testing)
</code></pre>

<pre><code>## [1] 11776   160
</code></pre>

<pre><code>## [1] 7846  160
</code></pre>

<p>2) Secondly, I took a look at the data using summary command (and also in a spreadsheet application) and I realized that there is a lot of missing values or NAN values. It was specific for entire columns, therefore I decided to select only columns which seemed usable. I selected the predictors using following code:</p>

<pre><code class="r">keeps &lt;- c(
&quot;num_window&quot;,  &quot;roll_belt&quot;, &quot;pitch_belt&quot;,   &quot;yaw_belt&quot;, &quot;total_accel_belt&quot;,
&quot;gyros_belt_x&quot;, &quot;gyros_belt_y&quot;, &quot;gyros_belt_z&quot;, &quot;accel_belt_x&quot;, &quot;accel_belt_y&quot;,
&quot;accel_belt_z&quot;, &quot;magnet_belt_x&quot;,    &quot;magnet_belt_y&quot;,    &quot;magnet_belt_z&quot;,    &quot;roll_arm&quot;, 
&quot;pitch_arm&quot;,    &quot;yaw_arm&quot;,      &quot;total_accel_arm&quot;, &quot;gyros_arm_x&quot;,   &quot;gyros_arm_y&quot;,  &quot;gyros_arm_z&quot;,
&quot;accel_arm_x&quot;,  &quot;accel_arm_y&quot;,  &quot;accel_arm_z&quot;,  &quot;magnet_arm_x&quot;, &quot;magnet_arm_y&quot;, 
&quot;magnet_arm_z&quot;, &quot;roll_dumbbell&quot;,    &quot;pitch_dumbbell&quot;,   &quot;yaw_dumbbell&quot;, &quot;total_accel_dumbbell&quot;,
&quot;gyros_dumbbell_x&quot;, &quot;gyros_dumbbell_y&quot;, &quot;gyros_dumbbell_z&quot;, &quot;accel_dumbbell_x&quot;,
&quot;accel_dumbbell_y&quot;, &quot;accel_dumbbell_z&quot;, &quot;magnet_dumbbell_x&quot;,    &quot;magnet_dumbbell_y&quot;,
&quot;magnet_dumbbell_z&quot;,    &quot;roll_forearm&quot;,     &quot;pitch_forearm&quot;,        &quot;yaw_forearm&quot;,
&quot;gyros_forearm_x&quot;,  &quot;gyros_forearm_y&quot;,  &quot;gyros_forearm_z&quot;,  &quot;accel_forearm_x&quot;,  
&quot;accel_forearm_y&quot;,  &quot;accel_forearm_z&quot;,  &quot;magnet_forearm_x&quot;, &quot;magnet_forearm_y&quot;,
&quot;magnet_forearm_z&quot;, &quot;classe&quot;
)


training_selection = training[keeps]
#summary(training_selection)
</code></pre>

<p>3) Then I displayed some plot of predictors that seemd to be general and important, such as &quot;total_accel_belt&quot; or &quot;total_accel_arm&quot; and &quot;total_accel_dumbbell&quot;. The dependences weren´t strong and it seemed  that the model has to be based on a bit advanced algorithm. Therefore I decided to use a non linear and advanced algorithm - Random forests. I am attaching one graph from visualization of the features. </p>

<p><img src="figure/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3"> </p>

<p>4) Then I fitted the Random forest model using following code. In preprocessing, I set all the NA values to be removed (I had been removing the columns in previous preprocessing. However, it could happen that some NA values rested in the data). In this point I tried also PCA in preprocessing (to reduce computational demands) but it reduced the accuracy a lot. It confirms an assumption that PCA is useful especially for linear models. I left default settings for train controlling (Bootstrapping) as well as the metrics to maximalize (Accuracy, RMSE).  </p>

<pre><code class="r">args(trainControl)
</code></pre>

<pre><code>## function (method = &quot;boot&quot;, number = ifelse(grepl(&quot;cv&quot;, method), 
##     10, 25), repeats = ifelse(grepl(&quot;cv&quot;, method), 1, number), 
##     p = 0.75, initialWindow = NULL, horizon = 1, fixedWindow = TRUE, 
##     verboseIter = FALSE, returnData = TRUE, returnResamp = &quot;final&quot;, 
##     savePredictions = FALSE, classProbs = FALSE, summaryFunction = defaultSummary, 
##     selectionFunction = &quot;best&quot;, preProcOptions = list(thresh = 0.95, 
##         ICAcomp = 3, k = 5), index = NULL, indexOut = NULL, timingSamps = 0, 
##     predictionBounds = rep(FALSE, 2), seeds = NA, adaptive = list(min = 5, 
##         alpha = 0.05, method = &quot;gls&quot;, complete = TRUE), allowParallel = TRUE) 
## NULL
</code></pre>

<pre><code class="r">modelFit &lt;- train(classe ~.,data=training_selection,preProcess.na.remove = TRUE, method=&quot;rf&quot;)
modelFit
</code></pre>

<pre><code>
## 	Random Forest 

## 	11776 samples
##	52 predictors
##	5 classes: 'A', 'B', 'C', 'D', 'E' 
##
##	No pre-processing
##	Resampling: Bootstrapped (25 reps) 
##
##	Summary of sample sizes: 11776, 11776, 11776, 11776, 11776, 11776, ... 
##
##	Resampling results across tuning parameters:
##
##  mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
##  2     0.99      0.987  0.00147      0.00186 
##  27    0.995     0.994  0.0015       0.00189 
##  52    0.992     0.989  0.00294      0.00373 

##Accuracy was used to select the optimal model using  the largest value.
##The final value used for the model was mtry = 27. 
</code></pre>

<pre><code class="r">modelFit$finalModel
</code></pre>

<pre><code>
##	Call:
##	randomForest(x = x, y = y, mtry = param$mtry, preProcess.na.remove = TRUE) 
##               Type of random forest: classification
##                     Number of trees: 500
##	No. of variables tried at each split: 27
##
##        OOB estimate of  error rate: 0.29%
##	Confusion matrix:
##  A    B    C    D    E  class.error
##	A 3346    1    0    0    1 0.0005973716
##	B    6 2268    4    1    0 0.0048266784
##	C    0    5 2049    0    0 0.0024342746
##	D    0    0    9 1920    1 0.0051813472
##	E    0    1    0    5 2159 0.0027713626 
</code></pre>

<p>5) Then I predicted the classes for my testing set (40% of given training set) and I created a confusion matrix. The statistics didn´t vary a lot from the previous ModelFit statistics. It shows that algorithm works well also for an independent data.</p>

<pre><code class="r">predictions &lt;-  confusionMatrix(predictions,testing$classe)
</code></pre>

<pre><code>
## Confusion Matrix and Statistics
##
##         Reference
## Prediction    A    B    C    D    E
##         A 2232   11    0    0    0
##         B    0 1507    5    0    0
##         C    0    0 1363    4    0
##         D    0    0    0 1282    2
##         E    0    0    0    0 1440
## 
## Overall Statistics
##                                          
##               Accuracy : 0.9972          
##                 95% CI : (0.9958, 0.9982)
##    No Information Rate : 0.2845          
##    P-Value [Acc > NIR] : < 2.2e-16       
##                                          
##                  Kappa : 0.9965          
## Mcnemar's Test P-Value : NA              
##
## Statistics by Class:
##
##                     Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9928   0.9963   0.9969   0.9986
## Specificity            0.9980   0.9992   0.9994   0.9997   1.0000
## Pos Pred Value         0.9951   0.9967   0.9971   0.9984   1.0000
## Neg Pred Value         1.0000   0.9983   0.9992   0.9994   0.9997
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2845   0.1921   0.1737   0.1634   0.1835
## Detection Prevalence   0.2859   0.1927   0.1742   0.1637   0.1835
## Balanced Accuracy      0.9990   0.9960   0.9979   0.9983   0.9993 
</code></pre>

<p>6) Finally, I predicted 20 given cases (given test set) using following code:</p>

<pre><code class="r">Data_TS = read.csv(&quot;pml-testing.csv&quot;, header = TRUE, sep = &quot;,&quot; );
#summary(Data_TS)
predictions &lt;- predict(modelFit,newdata=Data_TS) 
predictions
</code></pre>

<pre><code> ## [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>



</body>

</html>
